{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Matrix Addition Triton Implementation (Day 2): High-Performance Element-wise Add on 2D Grids\n",
    "Math: C[i, j] = A[i, j] + B[i, j] for i ∈ [0, M), j ∈ [0, N)\n",
    "Inputs / Outputs: A[M, N], B[M, N] -> C[M, N] contiguous row-major tensors\n",
    "Assumptions: M, N > 0; tensors contiguous on CUDA device; shapes and dtypes match\n",
    "Parallel Strategy: 2D grid where each Triton program processes a BLOCK_M × BLOCK_N tile\n",
    "Mixed Precision Policy: FP16/BF16 storage allowed, accumulation in same dtype; FP32 recommended for validation\n",
    "Distributed Hooks: Can be wrapped with data-parallel all-reduce on gradients or outputs\n",
    "Complexity: O(MN) FLOPs, O(3 * M * N * sizeof(dtype)) bytes moved\n",
    "Test Vectors: Deterministic random matrices for sizes like 32×32, 512×512 with max|Δ| < 1e-5 in FP32\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 16}, num_warps=4),\n",
    "        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32}, num_warps=4),\n",
    "        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32}, num_warps=8),\n",
    "        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=8),\n",
    "    ],\n",
    "    key=['M', 'N'],\n",
    ")\n",
    "@triton.jit\n",
    "def matrix_add_kernel(\n",
    "    a_ptr,\n",
    "    b_ptr,\n",
    "    c_ptr,\n",
    "    M,\n",
    "    N,\n",
    "    stride_am,\n",
    "    stride_an,\n",
    "    stride_bm,\n",
    "    stride_bn,\n",
    "    stride_cm,\n",
    "    stride_cn,\n",
    "    BLOCK_M: tl.constexpr,\n",
    "    BLOCK_N: tl.constexpr,\n",
    "):\n",
    "    \"\"\"\n",
    "    2D tiled matrix addition kernel.\n",
    "    Memory layout: row-major (stride_am = stride_bm = stride_cm = N, stride_an = stride_bn = stride_cn = 1).\n",
    "    \"\"\"\n",
    "    pid_m = tl.program_id(axis=0)\n",
    "    pid_n = tl.program_id(axis=1)\n",
    "\n",
    "    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)[:, None]\n",
    "    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)[None, :]\n",
    "\n",
    "    mask = (offs_m < M) & (offs_n < N)\n",
    "\n",
    "    a = tl.load(a_ptr + offs_m * stride_am + offs_n * stride_an, mask=mask, other=0.0)\n",
    "    b = tl.load(b_ptr + offs_m * stride_bm + offs_n * stride_bn, mask=mask, other=0.0)\n",
    "    c = a + b\n",
    "\n",
    "    tl.store(c_ptr + offs_m * stride_cm + offs_n * stride_cn, c, mask=mask)\n",
    "\n",
    "\n",
    "def _validate_inputs(a: torch.Tensor, b: torch.Tensor) -> (int, int):\n",
    "    assert a.device.type == \"cuda\", \"Inputs must be on CUDA device\"\n",
    "    assert b.device.type == \"cuda\", \"Inputs must be on CUDA device\"\n",
    "    assert a.shape == b.shape, \"Inputs must have the same shape\"\n",
    "    assert a.dim() == 2, \"Inputs must be 2D tensors [M, N]\"\n",
    "    assert a.dtype == b.dtype, \"Inputs must share dtype\"\n",
    "    assert a.is_contiguous(), \"Input A must be contiguous\"\n",
    "    assert b.is_contiguous(), \"Input B must be contiguous\"\n",
    "    M, N = a.shape\n",
    "    assert M > 0 and N > 0, \"Matrix dimensions must be > 0\"\n",
    "    return M, N\n",
    "\n",
    "\n",
    "def matrix_add_triton(\n",
    "    a: torch.Tensor,\n",
    "    b: torch.Tensor,\n",
    "    *,\n",
    "    block_m: int = 32,\n",
    "    block_n: int = 32,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Public API: matrix addition using Triton kernel.\n",
    "    \"\"\"\n",
    "    M, N = _validate_inputs(a, b)\n",
    "    c = torch.empty_like(a)\n",
    "\n",
    "    grid = (\n",
    "        triton.cdiv(M, block_m),\n",
    "        triton.cdiv(N, block_n),\n",
    "    )\n",
    "\n",
    "    stride_am = a.stride(0)\n",
    "    stride_an = a.stride(1)\n",
    "    stride_bm = b.stride(0)\n",
    "    stride_bn = b.stride(1)\n",
    "    stride_cm = c.stride(0)\n",
    "    stride_cn = c.stride(1)\n",
    "\n",
    "    matrix_add_kernel[grid](\n",
    "        a,\n",
    "        b,\n",
    "        c,\n",
    "        M,\n",
    "        N,\n",
    "        stride_am,\n",
    "        stride_an,\n",
    "        stride_bm,\n",
    "        stride_bn,\n",
    "        stride_cm,\n",
    "        stride_cn,\n",
    "        BLOCK_M=block_m,\n",
    "        BLOCK_N=block_n,\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "class MatrixAddModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch nn.Module wrapper to plug Day 2 matrix add into larger models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_m: int = 32, block_n: int = 32):\n",
    "        super().__init__()\n",
    "        self.block_m = block_m\n",
    "        self.block_n = block_n\n",
    "\n",
    "    def forward(self, a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "        return matrix_add_triton(a, b, block_m=self.block_m, block_n=self.block_n)\n",
    "\n",
    "\n",
    "def _run_correctness_tests() -> None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device.type != \"cuda\":\n",
    "        print(\"CUDA not available; skipping Triton tests.\")\n",
    "        return\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    dtypes = [torch.float32, torch.float16]\n",
    "    shapes = [(32, 32), (128, 128), (512, 512)]\n",
    "\n",
    "    for dtype in dtypes:\n",
    "        for (M, N) in shapes:\n",
    "            a = torch.randn(M, N, device=device, dtype=dtype)\n",
    "            b = torch.randn(M, N, device=device, dtype=dtype)\n",
    "            ref = a + b\n",
    "\n",
    "            out = matrix_add_triton(a, b, block_m=32, block_n=32)\n",
    "            torch.testing.assert_close(out, ref, rtol=1e-4, atol=1e-4)\n",
    "            max_diff = (out - ref).abs().max().item()\n",
    "            print(f\"[Day2][OK] M={M}, N={N}, dtype={dtype}, max_diff={max_diff:.2e}\")\n",
    "\n",
    "\n",
    "def benchmark_matrix_add(\n",
    "    shapes: Optional[List[tuple]] = None,\n",
    "    dtype: torch.dtype = torch.float32,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    if shapes is None:\n",
    "        shapes = [(256, 256), (512, 512), (1024, 1024), (2048, 2048)]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device.type != \"cuda\":\n",
    "        print(\"CUDA not available; skipping benchmark.\")\n",
    "        return []\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    results: List[Dict[str, Any]] = []\n",
    "\n",
    "    for (M, N) in shapes:\n",
    "        a = torch.randn(M, N, device=device, dtype=dtype)\n",
    "        b = torch.randn(M, N, device=device, dtype=dtype)\n",
    "\n",
    "        # Warmup\n",
    "        for _ in range(10):\n",
    "            _ = matrix_add_triton(a, b, block_m=32, block_n=32)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        iters = 100\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(iters):\n",
    "            out = matrix_add_triton(a, b, block_m=32, block_n=32)\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed_ms = (time.perf_counter() - start) * 1e3 / iters\n",
    "\n",
    "        ref = a + b\n",
    "        torch.testing.assert_close(out, ref, rtol=1e-4, atol=1e-4)\n",
    "\n",
    "        num_el = M * N\n",
    "        gflops = (num_el / (elapsed_ms / 1e3)) / 1e9\n",
    "        bandwidth = (3 * num_el * a.element_size()) / (elapsed_ms / 1e3) / 1e9\n",
    "\n",
    "        print(\n",
    "            f\"[Day2][BENCH] M={M}, N={N}, dtype={dtype}, time={elapsed_ms:.3f} ms, \"\n",
    "            f\"GFLOPS={gflops:.2f}, BW={bandwidth:.2f} GB/s\"\n",
    "        )\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"M\": M,\n",
    "                \"N\": N,\n",
    "                \"dtype\": str(dtype),\n",
    "                \"time_ms\": elapsed_ms,\n",
    "                \"gflops\": gflops,\n",
    "                \"bandwidth_gb_s\": bandwidth,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _run_correctness_tests()\n",
    "    benchmark_matrix_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67468f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
